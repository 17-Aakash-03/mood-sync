cat << 'EOF' > README.md
# Mood Sync: AI-Powered Emotion & Media Recommendation System ðŸŽ­

**[View Live App](https://mood-sync-aakash.streamlit.app)**

## About the Project
**Mood Sync** is an intelligent, full-stack web application designed to bridge the gap between human emotion and digital experiences. Unlike static recommendation engines that rely on manual input or search history, Mood Sync uses **Computer Vision and Artificial Intelligence** to analyze your facial expressions in real-time.

By detecting your current emotional state (e.g., Happy, Sad, Angry, Sleepy), the system acts as a personalized digital companion: it instantly curates a matching environment of music playlists, movies, food, and activities to either amplify your joy or comfort your stress.

## Problems Solved
This project addresses three common gaps in personalized media consumption:

### Emotional Disconnect
Standard algorithms (like Spotify or Netflix) recommend content based on *past* behavior, not *current* feelings. Mood Sync solves this by using real-time biometric data to match your **present** emotional needs.

### Decision Paralysis
Users often spend more time scrolling for something to watch or listen to than actually enjoying it. This system removes the friction of choice by autonomously providing a curated "Vibe Check" and playlist.

### Detection Bias & Hallucinations
Standard AI models often hallucinate faces on inanimate objects (like boxes) or miss subtle negative emotions. This project implements a **Strict Detection Filter** (ignoring non-faces) and a **Priority Threshold Algorithm** to catch subtle expressions like Disgust or Fear that are usually missed.

## How It Works (The Logic)
The system operates on a **"Enhance â†’ Scan â†’ Analyze â†’ Curate"** cycle:

### Monitor & Enhance
The system captures a webcam frame and applies OpenCV filters (Contrast +30%, Sharpening) to ensure accurate detection even in low-light conditions.

### Analyze
It sends the data to the **Face++ Cognitive Services API**.
* It checks for 8 distinct emotions.
* It calculates "Eye Status" to detect drowsiness/sleepiness.

### Decision Engine
* **Safety Check:** If no human face is found, the system halts (preventing false results on objects).
* **Priority Logic:** A custom algorithm weighs specific emotions. For example, if "Disgust" is detected at >2% confidence, it overrides "Neutral," ensuring high sensitivity.

### Curate
Based on the final mood and the user's age group, the system queries a dynamic `MOOD_MAP` database to retrieve tailored playlists, YouTube links, and activity suggestions.

## Results
* **Reaction Time:** The system analyzes mood and delivers a full recommendation dashboard in under **2 seconds**.
* **Accuracy:** Successfully filters out inanimate objects (0% false positives on boxes/bottles).
* **Stability:** Implemented "Offline Fallbacks" for quotes to ensure the app never crashes if external text APIs go down.

## Tech Stack
* **Language:** Python 3.x
* **Frontend/Backend:** Streamlit Cloud
* **Computer Vision:** OpenCV (`cv2`)
* **Cloud AI:** Face++ Cognitive Services API
* **Security:** Streamlit Secrets Management (Encrypted API Keys)

## How to Run

### Prerequisites
* Python installed.
* A webcam.

### Install Required Libraries
```bash
pip install streamlit opencv-python-headless requests numpy
